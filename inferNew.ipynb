{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wh2cc_JEmt-v",
        "outputId": "475c9331-5302-4251-f32b-dc8c40d2dee0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WinError 2] The system cannot find the file specified: '/content/'\n",
            "d:\\misc\\Programming\\Projects\\HeadSwap\\HeadSwap-Clone\n"
          ]
        }
      ],
      "source": [
        "%cd /content/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJeiY4CimwqG",
        "outputId": "cb239cf1-28c8-4860-85e1-70ce80980959"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Feb 14 11:50:58 2024       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 551.23                 Driver Version: 551.23         CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                     TCC/WDDM  | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA GeForce GTX 1650      WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
            "| N/A    0C    P3              9W /   30W |       0MiB /   4096MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "! nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zrht_5zBm14h",
        "outputId": "22d904bd-baa0-4223-e0e0-8bffac3bdc5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WinError 3] The system cannot find the path specified: 'HeadSwap-Clone/process'\n",
            "d:\\misc\\Programming\\Projects\\HeadSwap\\HeadSwap-Clone\n"
          ]
        }
      ],
      "source": [
        "# ! git clone https://github.com/notAllMight1/HeadSwap-Clone.git\n",
        "%cd HeadSwap-Clone/process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTPA2jTPm5iV",
        "outputId": "2c0b9349-2231-4459-c19c-6831414a26ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/HeadSwap-Clone/process\n"
          ]
        }
      ],
      "source": [
        "%cd /content/HeadSwap-Clone/process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scriXxbFnPk8",
        "outputId": "51e4a926-2ad8-4e2a-8c7d-df399fbdbe7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/HeadSwap-Clone\n"
          ]
        }
      ],
      "source": [
        "cd /content/HeadSwap-Clone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlF_eU92nSZI",
        "outputId": "08fcff0d-e0c3-48e4-bcaf-024add99ef9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/HeadSwap-Clone/process\n"
          ]
        }
      ],
      "source": [
        "cd /content/HeadSwap-Clone/process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOPHyzlmnY80"
      },
      "outputs": [],
      "source": [
        " %run NewScript.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1v50ZA1nk7q",
        "outputId": "5a3ddce0-7d87-489e-d147-8b33cbb79984"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-02-13 08:55:08--  https://raw.githubusercontent.com/sicxu/Deep3DFaceRecon_pytorch/master/BFM/similarity_Lm3D_all.mat\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 994 [application/octet-stream]\n",
            "Saving to: ‘../pretrained_models/BFM/similarity_Lm3D_all.mat’\n",
            "\n",
            "\rsimilarity_Lm3D_all   0%[                    ]       0  --.-KB/s               \rsimilarity_Lm3D_all 100%[===================>]     994  --.-KB/s    in 0s      \n",
            "\n",
            "2024-02-13 08:55:09 (56.6 MB/s) - ‘../pretrained_models/BFM/similarity_Lm3D_all.mat’ saved [994/994]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! wget https://raw.githubusercontent.com/sicxu/Deep3DFaceRecon_pytorch/master/BFM/similarity_Lm3D_all.mat -P ../pretrained_models/BFM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08HHNJLBn_68",
        "outputId": "685f4f79-8eda-4d55-bef6-4524ece3e367"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"
          ]
        }
      ],
      "source": [
        "#@title Setup files downloader\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import os\n",
        "\n",
        "download_with_pydrive = True #@param {type:\"boolean\"}\n",
        "\n",
        "class Downloader(object):\n",
        "    def __init__(self, use_pydrive):\n",
        "        self.use_pydrive = use_pydrive\n",
        "        current_directory = os.getcwd()\n",
        "        self.save_dir = '../pretrained_models'\n",
        "        os.makedirs(self.save_dir, exist_ok=True)\n",
        "        if self.use_pydrive:\n",
        "            self.authenticate()\n",
        "\n",
        "    def authenticate(self):\n",
        "        auth.authenticate_user()\n",
        "        gauth = GoogleAuth()\n",
        "        gauth.credentials = GoogleCredentials.get_application_default()\n",
        "        self.drive = GoogleDrive(gauth)\n",
        "\n",
        "    def download_file(self, file_id, file_name):\n",
        "        file_dst = f'{self.save_dir}/{file_name}'\n",
        "        if os.path.exists(file_dst):\n",
        "            print(f'{file_name} already exists!')\n",
        "            return\n",
        "        if self.use_pydrive:\n",
        "            downloaded = self.drive.CreateFile({'id':file_id})\n",
        "            downloaded.FetchMetadata(fetch_all=True)\n",
        "            downloaded.GetContentFile(file_dst)\n",
        "        else:\n",
        "            !gdown --id $file_id -O $file_dst\n",
        "\n",
        "downloader = Downloader(download_with_pydrive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3arr3uiCoJZa"
      },
      "outputs": [],
      "source": [
        "#@title Download epoch_20\n",
        "MODEL_PATHS = {\"id\": \"1BlDBB4dLLrlN3cJhVL4nmrd_g6Jx6uP0\", \"name\": \"epoch_20.pth\"}\n",
        "\n",
        "downloader.download_file(file_id=MODEL_PATHS[\"id\"], file_name=MODEL_PATHS[\"name\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBuinmDboXHw",
        "outputId": "4e589ad8-68fb-494a-8f24-a05a3e5cfa26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/HeadSwap-Clone/pretrained_models\n",
            "Archive:  face.zip\n",
            "   creating: face/\n",
            "  inflating: face/epoch_00190_iteration_000400000_checkpoint.pt  \n",
            "  inflating: face/latest_checkpoint.txt  \n"
          ]
        }
      ],
      "source": [
        "MODEL_PATHS = {\"id\": \"1-0xOf6g58OmtKtEWJlU3VlnfRqPN9Uq7\", \"name\": \"face.zip\"}\n",
        "downloader.download_file(file_id=MODEL_PATHS[\"id\"], file_name=MODEL_PATHS[\"name\"])\n",
        "%cd ../pretrained_models\n",
        "! unzip -x face.zip\n",
        "! mv face/epoch_00190_iteration_000400000_checkpoint.pt ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTtaHWbPogSH",
        "outputId": "dbc9ede2-5c4a-4a0b-d9e6-86ba9fdcdd04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BFM\t\t\t  epoch_00190_iteration_000400000_checkpoint.pt  face\t   parsing.pth\n",
            "Blender-401-00012900.pth  epoch_20.pth\t\t\t\t\t face.zip  sr_cf.onnx\n"
          ]
        }
      ],
      "source": [
        "! ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcK_tDvkorIL",
        "outputId": "8c358141-103e-44b9-f4b7-949677b69364"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Collecting onnxruntime-gpu\n",
            "  Downloading onnxruntime_gpu-1.17.0-cp310-cp310-manylinux_2_28_x86_64.whl (192.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.1/192.1 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting face-alignment\n",
            "  Downloading face_alignment-1.4.1-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Collecting coloredlogs (from onnxruntime-gpu)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (23.5.26)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (23.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (3.20.3)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.10/dist-packages (from face-alignment) (1.11.4)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from face-alignment) (0.19.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from face-alignment) (4.66.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from face-alignment) (0.58.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->face-alignment) (0.41.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2024.2.2)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->face-alignment) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->face-alignment) (2024.1.30)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->face-alignment) (1.5.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime-gpu, face-alignment\n",
            "Successfully installed coloredlogs-15.0.1 face-alignment-1.4.1 humanfriendly-10.0 onnxruntime-gpu-1.17.0\n"
          ]
        }
      ],
      "source": [
        "! pip install torch torchvision numpy opencv-python onnxruntime-gpu face-alignment==1.1.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTG28G0houSL",
        "outputId": "e887319b-462e-457d-ccff-146ab8ab9c23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/HeadSwap-Clone\n"
          ]
        }
      ],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOIr9INBo2v1"
      },
      "outputs": [],
      "source": [
        "from model.AlignModule.generator import FaceGenerator\n",
        "from model.BlendModule.generator import Generator as Decoder\n",
        "from model.AlignModule.config import Params as AlignParams\n",
        "from model.BlendModule.config import Params as BlendParams\n",
        "from model.third.faceParsing.model import BiSeNet\n",
        "import torchvision.transforms.functional as TF\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pdb\n",
        "from process.process_func import Process\n",
        "from process.process_utils import *\n",
        "import os\n",
        "import onnxruntime as ort\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ll48EZho458"
      },
      "outputs": [],
      "source": [
        "class Infer(Process):\n",
        "    def __init__(self,align_path,blend_path,parsing_path,params_path,bfm_folder):\n",
        "        Process.__init__(self,params_path,bfm_folder)\n",
        "        align_params = AlignParams()\n",
        "        blend_params = BlendParams()\n",
        "        self.device = 'cpu'\n",
        "        if torch.cuda.is_available():\n",
        "            self.device = 'cuda'\n",
        "\n",
        "        self.parsing = BiSeNet(n_classes=19).to(self.device)\n",
        "\n",
        "        self.netG = FaceGenerator(align_params).to(self.device)\n",
        "        self.decoder = Decoder(blend_params).to(self.device)\n",
        "\n",
        "        self.loadModel(align_path,blend_path,parsing_path)\n",
        "        self.eval_model(self.netG,self.decoder,self.parsing)\n",
        "\n",
        "\n",
        "        self.ort_session_sr = ort.InferenceSession('./pretrained_models/sr_cf.onnx', providers=['CPUExecutionProvider'])\n",
        "\n",
        "    def run(self,src_img_path_list,tgt_img_path_list,save_base,crop_align=False,cat=False):\n",
        "        os.makedirs(save_base,exist_ok=True)\n",
        "        i = 0\n",
        "        for src_img_path,tgt_img_path in zip(src_img_path_list,tgt_img_path_list):\n",
        "            gen = self.run_single(src_img_path,tgt_img_path,crop_align=crop_align,cat=cat)\n",
        "            img_name = os.path.splitext(os.path.basename(src_img_path))[0]+'-' + \\\n",
        "                        os.path.splitext(os.path.basename(tgt_img_path))[0]+'.png'\n",
        "            cv2.imwrite(os.path.join(save_base,img_name),gen)\n",
        "            print('\\rhave done %04d'%i,end='',flush=True)\n",
        "            i += 1\n",
        "        print()\n",
        "    def run_single(self,src_img_path,tgt_img_path,crop_align=False,cat=False):\n",
        "\n",
        "        tgt_img = cv2.imread(tgt_img_path)\n",
        "        tgt_align = tgt_img.copy()\n",
        "\n",
        "        tgt_align,info = self.preprocess_align(tgt_img)\n",
        "        if tgt_align is None:\n",
        "            return None\n",
        "\n",
        "        src_img = cv2.imread(src_img_path)\n",
        "        src_align = src_img\n",
        "        if crop_align:\n",
        "            src_align,_ = self.preprocess_align(src_img,top_scale=0.55)\n",
        "\n",
        "        src_inp = self.preprocess(src_align)\n",
        "        tgt_inp = self.preprocess(tgt_align)\n",
        "\n",
        "        tgt_params = self.get_params(cv2.resize(tgt_align,(256,256)),\n",
        "                                info['rotated_lmk']/2.0).unsqueeze(0)\n",
        "\n",
        "        gen = self.forward(src_inp,tgt_inp,tgt_params)\n",
        "\n",
        "        gen = self.postprocess(gen[0])\n",
        "        gen = self.run_sr(gen)\n",
        "        mask = self.mask\n",
        "        final = gen\n",
        "        # gen = color_transfer2(tgt_align,gen)\n",
        "\n",
        "        RotateMatrix = info['im'][:2]\n",
        "        mask = info['mask'][...,0]\n",
        "\n",
        "        rotate_gen = cv2.warpAffine(gen, RotateMatrix, (tgt_img.shape[1], tgt_img.shape[0]))\n",
        "        mask = cv2.warpAffine(mask, RotateMatrix, (tgt_img.shape[1], tgt_img.shape[0])) * 1.0\n",
        "\n",
        "        # ori_mask = mask.copy()\n",
        "        kernel2 = cv2.getStructuringElement(cv2.MORPH_RECT,(17, 17))\n",
        "        # mask = cv2.dilate(mask*1.0,kernel2)\n",
        "        mask = cv2.erode(mask*1.0,kernel2)\n",
        "        # mask = cv2.GaussianBlur(mask*255.0, (21, 21), 0) / 255.0\n",
        "        mask = cv2.blur(mask*1.0, (15, 15), 0) / 255.0\n",
        "        mask = np.clip(mask,0,1.0)[:,:,np.newaxis]\n",
        "\n",
        "        # pdb.set_trace()\n",
        "        final = rotate_gen * mask + tgt_img * (1-mask)\n",
        "\n",
        "        if cat:\n",
        "            final = np.concatenate([tgt_img,final],1)\n",
        "            final[-256:,:256] = cv2.resize(src_align,(256,256))\n",
        "\n",
        "        return final\n",
        "\n",
        "    def forward(self,xs,xt,params):\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # xg = self.netG(F.adaptive_avg_pool2d(xs,256),\n",
        "            #                 F.adaptive_avg_pool2d(xt,256),\n",
        "            #                 params)['fake_image']\n",
        "            xg = F.adaptive_avg_pool2d(self.netG(F.adaptive_avg_pool2d(xs,256),\n",
        "                            F.adaptive_avg_pool2d(xt,256),\n",
        "                            params)['fake_image'],512)\n",
        "\n",
        "\n",
        "            M_a = self.parsing(self.preprocess_parsing(xg))\n",
        "\n",
        "            M_t = self.parsing(self.preprocess_parsing(xt))\n",
        "\n",
        "            M_a = self.postprocess_parsing(M_a)\n",
        "            M_t = self.postprocess_parsing(M_t)\n",
        "            # xg[M_a.repeat(1,3,1,1)==0] = -0.5\n",
        "            # xg[M_a.repeat(1,3,1,1)==16] = 0.6\n",
        "            xg_gray = TF.rgb_to_grayscale(xg,num_output_channels=1)\n",
        "            fake = self.decoder(xg,xg_gray,xt,M_a,M_t,xt,train=False)\n",
        "\n",
        "\n",
        "            gen_mask = self.parsing(self.preprocess_parsing(fake))\n",
        "            gen_mask = self.postprocess_parsing(gen_mask)\n",
        "            gen_mask = gen_mask[0][0].cpu().numpy()\n",
        "            mask_t = M_t[0][0].cpu().numpy()\n",
        "            mask = np.zeros_like(gen_mask)\n",
        "            for i in [1,2,3,4,5,6,7,8,9,10,11,12,13,17,18]:\n",
        "                mask[gen_mask==i] = 1.0\n",
        "                mask[mask_t==i] = 1.0\n",
        "\n",
        "            self.mask = mask\n",
        "        return fake\n",
        "\n",
        "    def run_sr(self,input_np):\n",
        "        input_np = cv2.cvtColor(input_np, cv2.COLOR_BGR2RGB)\n",
        "        # prepare data\n",
        "        input_np = input_np.transpose((2,0,1))\n",
        "        input_np = np.array(input_np[np.newaxis, :])\n",
        "        outputs_onnx = self.ort_session_sr.run(None, {'input_image':input_np.astype(np.uint8)})\n",
        "\n",
        "        out_put_onnx = outputs_onnx[0]\n",
        "        outimg = out_put_onnx[0,...].transpose(1,2,0)\n",
        "        outimg = cv2.cvtColor(outimg, cv2.COLOR_BGR2RGB)\n",
        "        return outimg\n",
        "\n",
        "\n",
        "    def loadModel(self,align_path,blend_path,parsing_path):\n",
        "        ckpt = torch.load(align_path, map_location=lambda storage, loc: storage)\n",
        "        # self.netG.load_state_dict(ckpt['G'])\n",
        "        self.netG.load_state_dict(ckpt['net_G_ema'])\n",
        "\n",
        "        ckpt = torch.load(blend_path, map_location=lambda storage, loc: storage)\n",
        "        self.decoder.load_state_dict(ckpt['G'],strict=False)\n",
        "\n",
        "        self.parsing.load_state_dict(torch.load(parsing_path))\n",
        "\n",
        "\n",
        "    def eval_model(self,*args):\n",
        "        for arg in args:\n",
        "            arg.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "1BS-wMKfo-TE",
        "outputId": "9881c5b7-2b87-4023-a6cd-e35e49356896"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "_3D",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-6023005ed194>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = Infer(\n\u001b[0m\u001b[1;32m      2\u001b[0m             \u001b[0;31m# 'checkpoint/Aligner/058-00008100.pth',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0;34m'pretrained_models/epoch_00190_iteration_000400000_checkpoint.pt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0;34m'pretrained_models/Blender-401-00012900.pth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;34m'pretrained_models/parsing.pth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-267e6b1e17d7>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, align_path, blend_path, parsing_path, params_path, bfm_folder)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mInfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malign_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mblend_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparsing_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbfm_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbfm_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0malign_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAlignParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mblend_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlendParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/HeadSwap-Clone/process/process_func.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params_path, bfm_folder)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_detector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFaceDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlmk_detector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_alignment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFaceAlignment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface_alignment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLandmarksType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_3D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflip_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;31m# 3dmm params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParamsModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReconNetWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/enum.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_member_map_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: _3D"
          ]
        }
      ],
      "source": [
        "\n",
        "model = Infer(\n",
        "            # 'checkpoint/Aligner/058-00008100.pth',\n",
        "            'pretrained_models/epoch_00190_iteration_000400000_checkpoint.pt',\n",
        "            'pretrained_models/Blender-401-00012900.pth',\n",
        "            'pretrained_models/parsing.pth',\n",
        "            'pretrained_models/epoch_20.pth',\n",
        "            'pretrained_models/BFM')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_KVkJ1Sr_cI",
        "outputId": "d60ebc3b-d3cd-4bd0-adcc-d179a231da65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: face_alignment in /usr/local/lib/python3.10/dist-packages (1.4.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from face_alignment) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_alignment) (1.23.5)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.10/dist-packages (from face_alignment) (1.11.4)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from face_alignment) (0.19.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from face_alignment) (4.8.0.76)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from face_alignment) (4.66.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from face_alignment) (0.58.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->face_alignment) (0.41.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->face_alignment) (3.2.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->face_alignment) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->face_alignment) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->face_alignment) (2024.1.30)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->face_alignment) (1.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->face_alignment) (23.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->face_alignment) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->face_alignment) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->face_alignment) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->face_alignment) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->face_alignment) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->face_alignment) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->face_alignment) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->face_alignment) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install face_alignment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cz91m1RLsNQq",
        "outputId": "e4712efb-0ae9-49ad-9a27-3436b578de78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['FaceAlignment', 'LandmarksType', 'NetworkSize', '__author__', '__builtins__', '__cached__', '__doc__', '__email__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', 'api', 'detection', 'folder_data', 'utils']\n"
          ]
        }
      ],
      "source": [
        "import face_alignment\n",
        "\n",
        "print(dir(face_alignment))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_orHqk_qMqr",
        "outputId": "37521a7e-880e-4372-bafa-0fd1318282ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Feb 13 08:58:12 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P0              27W /  70W |    205MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xR4iGWH1p2Kd"
      },
      "source": [
        "Upload Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "1hjXeWYdpB6l",
        "outputId": "19678602-8c23-4fdb-a5d9-92e368ef24b2"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-23-85d1df7cce95>, line 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSyntaxError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/compilerop.py\u001b[0m in \u001b[0;36mast_parse\u001b[0;34m(self, source, filename, symbol)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mArguments\u001b[0m \u001b[0mare\u001b[0m \u001b[0mexactly\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mstandard\u001b[0m \u001b[0mlibrary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         and are passed to the built-in compile function.\"\"\"\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mPyCF_ONLY_AST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_compiler_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSyntaxError\u001b[0m: invalid syntax (<ipython-input-23-85d1df7cce95>, line 1)"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import shutil\n",
        "import os.path as osp\n",
        "\n",
        "\n",
        "uploaded_imgs_path = 'assets'\n",
        "if not osp.exists(uploaded_imgs_path) : os.makedirs(uploaded_imgs_path)\n",
        "\n",
        "def upload_img():\n",
        "  uploaded_img = files.upload()\n",
        "  uploadded_img_name = list(uploaded_img.keys())[0]\n",
        "\n",
        "  !mv \"{uploadded_img_name}\" \"{uploaded_imgs_path}\"\n",
        "\n",
        "  print(f\"move file {uploadded_img_name} to {uploaded_imgs_path} \")\n",
        "  return os.path.join(uploaded_imgs_path,uploadded_img_name)\n",
        "# print(uploaded_img.keys())\n",
        "# for fn in uploaded_img.keys():\n",
        "#   print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "#       name=fn, length=len(uploaded_img[fn])))\n",
        "up_mode = 0 #@param [0, 1]\n",
        "if up_mode:\n",
        "  src = upload_img()\n",
        "  tgt = upload_img()\n",
        "else:\n",
        "  src = './assets/5.jpg'\n",
        "  tgt = 'assets/fe54875c-2cf0-4147-b08a-80552a9f46be.jpg'\n",
        "\n",
        "src_img = cv2.imread(src)\n",
        "cv2_imshow(src_img)\n",
        "tgt_img = cv2.imread(tgt)\n",
        "cv2_imshow(tgt_img)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDTjz7cCpzCl"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
